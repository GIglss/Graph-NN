{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphNN on Cora (Node Classification).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets for GNN\n",
        "- cora benchmark dataset \n",
        "- Open Graph benchmark dataset\n",
        "- Benchmarking-GNNs\n",
        "\n",
        "\n",
        "# Usefull resources for further study\n",
        "Blogs: \n",
        "- GCN by Thomas Kipf\n",
        "- GAT by Petar Velickovic\n",
        "- Graph Deep Learning by Michael Bronstein\n",
        "\n",
        "Guest lecture by Xavier Bresson for NYU's Deep Learning Course\n",
        "\n",
        "Libraries for Tensorflow: GraphNets, Spektral, DGL\n",
        "\n",
        "Book:\n",
        "- Graph Representation Learning by Will Hamilton\n",
        "\n",
        "University Courses: \n",
        "- CS224W at Standford\n",
        "- COMP766 at McGill\n",
        "\n",
        "all compiled in: https://twitter.com/PetarV_93/status/1306689702020382720"
      ],
      "metadata": {
        "id": "Rc0QqA_omyco"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Gl83z5EzS_"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install tensorflow\n",
        "!pip install spektral # for graph representation learning used now for loading and preprocessing the dataset in a nice form\n",
        "# spektral allows us to get acces to adjacency matrix, feature matrix, labels (topic of each paper), mask arrays (which nodes belong to the train, val, test set) of the graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z55l0Gq-FutQ",
        "outputId": "9ef49a52-01bc-4ca3-ef11-3e00f9c20769"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Collecting spektral\n",
            "  Downloading spektral-1.0.8-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from spektral) (1.1.0)\n",
            "Collecting numpy<1.20\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 17.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from spektral) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spektral) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from spektral) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from spektral) (2.23.0)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spektral) (2.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from spektral) (2.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from spektral) (4.2.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spektral) (4.63.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (13.0.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.44.0)\n",
            "Collecting tensorflow>=2.1.0\n",
            "  Downloading tensorflow-2.7.1-cp37-cp37m-manylinux2010_x86_64.whl (495.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 495.0 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.24.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (2.0)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (0.37.1)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (3.10.0.2)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.1.0->spektral) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->spektral) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.1.0->spektral) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->spektral) (3.1.0)\n",
            "Installing collected packages: numpy, tensorflow-estimator, keras, gast, tensorflow, spektral\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 numpy-1.19.5 spektral-1.0.8 tensorflow-2.7.1 tensorflow-estimator-2.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "numpy",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import spektral"
      ],
      "metadata": {
        "id": "H-InzNtpGEi-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip list"
      ],
      "metadata": {
        "id": "qC7bPwI9QU7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adj, features, labels, train_mask, val_mask, test_mask = spektral.datasets.citation.load_data(dataset_name='cora')\n",
        "# for spektral == 1.0.8\n",
        "cora_dataset = spektral.datasets.citation.Citation(name='cora')\n",
        "test_mask = cora_dataset.mask_te\n",
        "train_mask = cora_dataset.mask_tr\n",
        "val_mask = cora_dataset.mask_va\n",
        "graph = cora_dataset.graphs[0] # zero since its just one graph inside, there could be more for other datasets\n",
        "features = graph.x\n",
        "adj = graph.a\n",
        "labels = graph.y\n",
        "\n",
        "\n",
        "# spektral retrieves in sparse format, for previous spektral versions\n",
        "# features = features.todense()\n",
        "  # also adj doesnt come with self edges, common thing to do at the beginning->\n",
        "  # add the identity matrix to de adj matrix to make sure is okay\n",
        "adj = adj.todense() + np.eye(adj.shape[0])\n",
        "\n",
        "# to make sure everything plays nicely with tensorflow, convert to 32bit floating number\n",
        "features = features.astype('float32')\n",
        "adj = adj.astype('float32')\n",
        "\n",
        "print('total nodes:', features.shape[0])\n",
        "print('total features for each node:', features.shape[1])\n",
        "print(adj.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "print('training nodes: ',np.sum(train_mask))\n",
        "print('validation nodes: ',np.sum(val_mask))\n",
        "print('test nodes: ',np.sum(test_mask))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6w2zMQ-GLp-",
        "outputId": "d2ae7623-06e2-4f87-af96-ffd574fcfa9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total nodes: 2708\n",
            "total features for each node: 1433\n",
            "(2708, 2708)\n",
            "(2708, 7)\n",
            "training nodes:  140\n",
            "validation nodes:  500\n",
            "test nodes:  1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# functions that will allow us to do loss and eval metrics for masked nodes\n",
        "def masked_softmax_cross_entropy(logits, labels, mask): # returns the crossentropy loss of the nodes of the graph ONLY taking nodes that are masked by the mask array\n",
        "  loss = tf.nn.softmax_cross_entropy_with_logits(logits= logits, labels=labels)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  mask /= tf.reduce_mean(mask)\n",
        "  loss *= mask\n",
        "  return tf.reduce_mean(loss)\n",
        "\n",
        "# accuracy metric over a mask\n",
        "def masked_accuracy(logits, lables, mask):\n",
        "  correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(labels, 1))\n",
        "  accuracy_all = tf.cast(correct_prediction, tf.float32)\n",
        "  mask = tf.cast(mask, tf.float32)\n",
        "  mask /= tf.reduce_mean(mask)\n",
        "  accuracy_all *= mask\n",
        "  return tf.reduce_mean(accuracy_all)"
      ],
      "metadata": {
        "id": "C2JA6uiGLQEO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definition of simple gnn layer\n",
        "  #node feature matrix,\n",
        "  #adjacency matrix,\n",
        "  #transformation that we will like to apply to every node\n",
        "  #activation function\n",
        "\n",
        "def gnn(fts, adj, transform, activation):\n",
        "  seq_fts = transform(fts) # transform each of the nodes individually\n",
        "  ret_fts = tf.matmul(adj, seq_fts) # recombine to neighborhoods\n",
        "  return activation(ret_fts) # apply activation function"
      ],
      "metadata": {
        "id": "thv6B7I5apau"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define 2 layer gnn to classify the cora dataset\n",
        "  #node feature matrix\n",
        "  #adj matrix\n",
        "  #gnn model function\n",
        "  #how many units we want our neural network to compute in each node\n",
        "  # how many epochs\n",
        "  # learning rate\n",
        "def train_cora(fts, adj, gnn_fn, units, epochs, lr):\n",
        "  lyr_1 = tf.keras.layers.Dense(units)\n",
        "  lyr_2 = tf.keras.layers.Dense(7) # classification of 7 classes\n",
        "\n",
        "  # define gnn that is used to solve this problem on a particular set of features and adjacencies\n",
        "  def cora_gnn(fts, adj):\n",
        "    hidden = gnn_fn(fts, adj, lyr_1, tf.nn.relu) # compute the hidden features on every node\n",
        "    # define our logits by applying the second graph nn layer which starts from the hidden features, and then the adj matrix\n",
        "    logits = gnn_fn(hidden, adj, lyr_2, tf.identity) # we use tf.identity as we don't want to transform (they are logits)\n",
        "    return logits # return predictions\n",
        "\n",
        "  # use of a standard optimization pipeline - Adam Optimizer\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "  # standard training pipeline with early stopping, for that, keep track of the validation data accuracy so far\n",
        "  best_accuracy = 0.0\n",
        "  for ep in range(epochs +1):\n",
        "    with tf.GradientTape() as t: # to record all the gradients - GradientTape\n",
        "      logits = cora_gnn(fts, adj) # apply cora_gnn to compute predictions at this step\n",
        "      loss = masked_softmax_cross_entropy(logits, labels, train_mask) # compute loss\n",
        "\n",
        "    # specify gradients to update variables based on this loss\n",
        "    variables = t.watched_variables() # get the variables that the GradientTape is watching\n",
        "    grads = t.gradient(loss, variables) # define gradients\n",
        "    optimizer.apply_gradients(zip(grads, variables)) # apply the optimizer to apply this gradients\n",
        "\n",
        "    # track validation and test accuracy\n",
        "    logits = cora_gnn(fts, adj) # after the gradients have been updated\n",
        "    val_accuracy = masked_accuracy(logits, labels, val_mask) # compute the validation accuracy as the masked accuracy on the logits against the labels\n",
        "    test_accuracy = masked_accuracy(logits, labels, test_mask)\n",
        "\n",
        "    if val_accuracy > best_accuracy:\n",
        "      best_accuracy = val_accuracy\n",
        "      print('Epoch', ep, '| Training loss:', loss.numpy(), '| Val accuracy:',\n",
        "            val_accuracy.numpy(), '| Test accuracy:', test_accuracy.numpy())\n"
      ],
      "metadata": {
        "id": "S6Z0UdbtbSf8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call just one line of code to try to train on the Cora data set for some particular adj matrix\n",
        "\n",
        "# by passing the raw adj matrix means that we're going to be multiplying the features with just 0 or 1 matrix ->\n",
        "  # Therefore implementing SUM-POOLING\n",
        "  # we're expecting this to have some problems with the scale of the features, and as a result it might not give us the best results possible\n",
        "train_cora(features, adj, gnn, 32, 200, 0.01)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md9u88M0faN0",
        "outputId": "df281779-eefe-4344-fa93-af68961b9992"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Training loss: 4.4897547 | Val accuracy: 0.22399999 | Test accuracy: 0.22400002\n",
            "Epoch 1 | Training loss: 7.0553784 | Val accuracy: 0.34399998 | Test accuracy: 0.39799997\n",
            "Epoch 3 | Training loss: 3.614131 | Val accuracy: 0.36999997 | Test accuracy: 0.39\n",
            "Epoch 4 | Training loss: 2.9831219 | Val accuracy: 0.406 | Test accuracy: 0.431\n",
            "Epoch 5 | Training loss: 2.6912107 | Val accuracy: 0.444 | Test accuracy: 0.44500002\n",
            "Epoch 7 | Training loss: 1.8758388 | Val accuracy: 0.47599998 | Test accuracy: 0.519\n",
            "Epoch 8 | Training loss: 1.3678852 | Val accuracy: 0.546 | Test accuracy: 0.57899994\n",
            "Epoch 9 | Training loss: 0.9143429 | Val accuracy: 0.59 | Test accuracy: 0.62299997\n",
            "Epoch 10 | Training loss: 0.62095714 | Val accuracy: 0.62 | Test accuracy: 0.665\n",
            "Epoch 11 | Training loss: 0.4301379 | Val accuracy: 0.66 | Test accuracy: 0.695\n",
            "Epoch 12 | Training loss: 0.32929707 | Val accuracy: 0.684 | Test accuracy: 0.70000005\n",
            "Epoch 13 | Training loss: 0.2792171 | Val accuracy: 0.702 | Test accuracy: 0.709\n",
            "Epoch 14 | Training loss: 0.27076045 | Val accuracy: 0.70799994 | Test accuracy: 0.715\n",
            "Epoch 35 | Training loss: 0.042980153 | Val accuracy: 0.71 | Test accuracy: 0.72\n",
            "Epoch 38 | Training loss: 0.033662852 | Val accuracy: 0.71199995 | Test accuracy: 0.721\n",
            "Epoch 60 | Training loss: 0.008954554 | Val accuracy: 0.714 | Test accuracy: 0.73599994\n",
            "Epoch 61 | Training loss: 0.0086021405 | Val accuracy: 0.716 | Test accuracy: 0.73499995\n",
            "Epoch 63 | Training loss: 0.007968519 | Val accuracy: 0.718 | Test accuracy: 0.73599994\n",
            "Epoch 79 | Training loss: 0.0049528778 | Val accuracy: 0.72 | Test accuracy: 0.73399997\n",
            "Epoch 88 | Training loss: 0.004068063 | Val accuracy: 0.722 | Test accuracy: 0.733\n",
            "Epoch 96 | Training loss: 0.003505203 | Val accuracy: 0.72400004 | Test accuracy: 0.73499995\n",
            "Epoch 145 | Training loss: 0.0018130669 | Val accuracy: 0.726 | Test accuracy: 0.732\n",
            "Epoch 168 | Training loss: 0.0014335734 | Val accuracy: 0.728 | Test accuracy: 0.732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verys useful thing to verify is that it's usefull to use the graph at all\n",
        "# so lets test it by using the identity matrix instead the adj matrix\n",
        "# This will basically render the operation of multiplying with the adj matrix as not really changing anything\n",
        "# so we just have basically a point-wise classifier in each of our nodes -> so a standard MLP model that is shared accross the vertices\n",
        "\n",
        "train_cora(features, tf.eye(adj.shape[0]), gnn, 32, 200, 0.01)\n",
        "\n",
        "# so we can see the progress is generally far more steady, but it doesn't actually end up surpassing around 50% or so\n",
        "# we can see that if you're not effectively exploiting the graph structure, \n",
        "# you're going to end up not completely capturing the interesting structure in your data \n",
        "# and this point-wise MLP will be unable to go beyond 50% testing_accuracy or so"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNtKg7wPfrtI",
        "outputId": "6c80df02-1fde-4c56-a951-d231cb64aa10"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Training loss: 1.9650178 | Val accuracy: 0.18399999 | Test accuracy: 0.21299998\n",
            "Epoch 1 | Training loss: 1.7205448 | Val accuracy: 0.27 | Test accuracy: 0.301\n",
            "Epoch 2 | Training loss: 1.514502 | Val accuracy: 0.334 | Test accuracy: 0.343\n",
            "Epoch 3 | Training loss: 1.2945721 | Val accuracy: 0.35999998 | Test accuracy: 0.376\n",
            "Epoch 4 | Training loss: 1.0721266 | Val accuracy: 0.38799998 | Test accuracy: 0.401\n",
            "Epoch 5 | Training loss: 0.86842245 | Val accuracy: 0.38999996 | Test accuracy: 0.41200003\n",
            "Epoch 6 | Training loss: 0.6934445 | Val accuracy: 0.40199998 | Test accuracy: 0.41999996\n",
            "Epoch 7 | Training loss: 0.5486387 | Val accuracy: 0.40999997 | Test accuracy: 0.431\n",
            "Epoch 8 | Training loss: 0.4328917 | Val accuracy: 0.424 | Test accuracy: 0.44499996\n",
            "Epoch 9 | Training loss: 0.3424882 | Val accuracy: 0.438 | Test accuracy: 0.45999998\n",
            "Epoch 10 | Training loss: 0.27245322 | Val accuracy: 0.45399997 | Test accuracy: 0.468\n",
            "Epoch 11 | Training loss: 0.21771894 | Val accuracy: 0.474 | Test accuracy: 0.47300002\n",
            "Epoch 13 | Training loss: 0.14004126 | Val accuracy: 0.488 | Test accuracy: 0.485\n",
            "Epoch 14 | Training loss: 0.11267692 | Val accuracy: 0.494 | Test accuracy: 0.49199998\n",
            "Epoch 15 | Training loss: 0.09122209 | Val accuracy: 0.50200003 | Test accuracy: 0.501\n",
            "Epoch 17 | Training loss: 0.061424322 | Val accuracy: 0.51799995 | Test accuracy: 0.515\n",
            "Epoch 18 | Training loss: 0.051188514 | Val accuracy: 0.52000004 | Test accuracy: 0.515\n",
            "Epoch 19 | Training loss: 0.043048922 | Val accuracy: 0.52199996 | Test accuracy: 0.519\n",
            "Epoch 21 | Training loss: 0.031091096 | Val accuracy: 0.528 | Test accuracy: 0.515\n",
            "Epoch 22 | Training loss: 0.026663348 | Val accuracy: 0.532 | Test accuracy: 0.518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have shown that the graph is actually useful by comparing the above models\n",
        "# lets explore more kinds of graph convolutional layers\n",
        "\n",
        "# The first one we can explore is MEAN-POOLING\n",
        "# so we can first compute the degree matrix as the degree of each node and then spread across the diagonal\n",
        "deg = tf.reduce_sum(adj, axis = 1)\n",
        "\n",
        "# and we can now rerun our train Cora setup using the features\n",
        "# dividing the adj matrix by the degree matrix, which is equivalent to multiplying to the inverse of the degree matrix\n",
        "# This will now give us a normalized propagation rule, which should hopefully deal with any exploding signal that we might have\n",
        "# And this should hopefully be more stable than the update we had before\n",
        "train_cora(features, adj / deg, gnn, 32, 200, 0.01)\n",
        "# we see that after some epocs is behaving better than the SUM-POOLING model, \n",
        "# The overall performance is more stable and strong improvement from the SUM-POOLING\n",
        "\n",
        "# this says that it is a good idea to normalize our adjacency matrix in this way"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc9CbrYshuZW",
        "outputId": "43c2a514-1273-4a6a-d527-301ab7d93ef7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Training loss: 1.9528046 | Val accuracy: 0.366 | Test accuracy: 0.439\n",
            "Epoch 1 | Training loss: 1.7760805 | Val accuracy: 0.532 | Test accuracy: 0.585\n",
            "Epoch 2 | Training loss: 1.5735261 | Val accuracy: 0.63 | Test accuracy: 0.684\n",
            "Epoch 3 | Training loss: 1.3514179 | Val accuracy: 0.69 | Test accuracy: 0.73099995\n",
            "Epoch 4 | Training loss: 1.136811 | Val accuracy: 0.73200005 | Test accuracy: 0.77399987\n",
            "Epoch 5 | Training loss: 0.9328334 | Val accuracy: 0.766 | Test accuracy: 0.8039999\n",
            "Epoch 6 | Training loss: 0.75224274 | Val accuracy: 0.7839999 | Test accuracy: 0.81799984\n",
            "Epoch 7 | Training loss: 0.60083675 | Val accuracy: 0.79199994 | Test accuracy: 0.8159998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And finally we're going to try out the specific version of the normalization \n",
        "# that Thomas Kipf has proposed in the Graph Convolution Network model\n",
        "# This requires us to compute one over the square root of the degree and \n",
        "# then multiply that on both sides with the adj matrix\n",
        "\n",
        "# So we can get the normalized adj matrix by first having this half normalized degree matrix\n",
        "norm_deg = tf.linalg.diag(1.0 / tf.sqrt(deg))\n",
        "# and then multiplying that with the product of the adj and the normalized degree matrix\n",
        "norm_adj = tf.matmul(norm_deg, tf.matmul(adj, norm_deg)) # so this is the equivalent of taking d to the minus 1/2 and then multiplying it with the adj matrix on both sides\n",
        "\n",
        "train_cora(features, norm_adj, gnn, 32, 200, 0.01)\n",
        "\n",
        "# In average you should not see a significant difference between this one and the division by degree, at least not in this dataset\n",
        "# but both imporove over the SUM-POOLING and are expected to perform roughly comparably in this particular setting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko_BQQcRjmkl",
        "outputId": "63c29362-76ce-4b18-ac9b-eb50ed30c5d8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Training loss: 1.9455462 | Val accuracy: 0.536 | Test accuracy: 0.574\n",
            "Epoch 1 | Training loss: 1.7705743 | Val accuracy: 0.628 | Test accuracy: 0.662\n",
            "Epoch 2 | Training loss: 1.5604495 | Val accuracy: 0.642 | Test accuracy: 0.66400003\n",
            "Epoch 3 | Training loss: 1.3300091 | Val accuracy: 0.658 | Test accuracy: 0.67800003\n",
            "Epoch 4 | Training loss: 1.1126056 | Val accuracy: 0.69 | Test accuracy: 0.70699996\n",
            "Epoch 5 | Training loss: 0.91319835 | Val accuracy: 0.73199993 | Test accuracy: 0.74399996\n",
            "Epoch 6 | Training loss: 0.7381033 | Val accuracy: 0.75600004 | Test accuracy: 0.7789999\n",
            "Epoch 7 | Training loss: 0.5881834 | Val accuracy: 0.77000004 | Test accuracy: 0.7999998\n",
            "Epoch 8 | Training loss: 0.46325633 | Val accuracy: 0.778 | Test accuracy: 0.8019998\n",
            "Epoch 9 | Training loss: 0.3614521 | Val accuracy: 0.782 | Test accuracy: 0.8069998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tFrPcBRXlbTW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}